{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6Zapjh8IFodxSUbhpcyeu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/221230003-coder/221230003-pengantar-ML/blob/main/221230003_Pengantar_ML_week_02_latihan_praktikum_2_numpy_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYTQP4gbapsW",
        "outputId": "e2a5a40b-f973-47c8-d73b-1ceb12d30599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy operations completed\n",
            "X_normalized:\n",
            " [[ 0.604418   -0.21979528  0.75746006  1.461092   -0.18919425]\n",
            " [-0.21141045  1.53420502  0.87977344 -0.62585547  0.53845484]\n",
            " [-0.46735006 -0.55422449  0.34303561 -2.13809665 -1.58578836]\n",
            " [-0.57771567 -1.1129603   0.41687036 -1.08519209 -1.2929218 ]\n",
            " [ 1.68601234 -0.30916828  0.16486193 -1.62640854 -0.47982667]]\n",
            "X_cleaned:\n",
            " [[ 0.604418   -0.21979528  0.75746006  1.461092   -0.18919425]\n",
            " [-0.21141045  1.53420502  0.87977344 -0.62585547  0.53845484]\n",
            " [-0.46735006 -0.55422449  0.34303561 -2.13809665 -1.58578836]\n",
            " [-0.57771567 -1.1129603   0.41687036 -1.08519209 -1.2929218 ]\n",
            " [ 1.68601234 -0.30916828  0.16486193 -1.62640854 -0.47982667]]\n",
            "One-hot labels:\n",
            " [[1 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# TODO 1: Normalisasi Z-score\n",
        "def z_score_normalization(data):\n",
        "    \"\"\"\n",
        "    Melakukan normalisasi Z-score pada data.\n",
        "    Rumus: (x - mean) / std\n",
        "    Input: np.ndarray\n",
        "    Output: np.ndarray dengan mean ~0 dan std ~1\n",
        "    \"\"\"\n",
        "    if not isinstance(data, np.ndarray):\n",
        "        raise TypeError(\"Input harus berupa NumPy array\")\n",
        "\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "\n",
        "    # Hindari pembagian dengan nol\n",
        "    std[std == 0] = 1\n",
        "\n",
        "    return (data - mean) / std\n",
        "\n",
        "\n",
        "# TODO 2: Handle outliers (clip values beyond 3 std)\n",
        "def handle_outliers(data, std_threshold=3):\n",
        "    \"\"\"\n",
        "    Menangani outlier dengan cara clipping.\n",
        "    Nilai di luar mean Â± threshold*std dipotong ke batas tersebut.\n",
        "    Input: np.ndarray\n",
        "    Output: np.ndarray tanpa outlier ekstrem\n",
        "    \"\"\"\n",
        "    if not isinstance(data, np.ndarray):\n",
        "        raise TypeError(\"Input harus berupa NumPy array\")\n",
        "\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "\n",
        "    lower_bound = mean - std_threshold * std\n",
        "    upper_bound = mean + std_threshold * std\n",
        "\n",
        "    return np.clip(data, lower_bound, upper_bound)\n",
        "\n",
        "\n",
        "# TODO 3: One-hot encoding untuk label kategorikal\n",
        "def one_hot_encoding(labels):\n",
        "    \"\"\"\n",
        "    Konversi label kategorikal ke one-hot encoding.\n",
        "    Input: array 1D (contoh: [0,1,2,0])\n",
        "    Output: array 2D one-hot\n",
        "    \"\"\"\n",
        "    if not isinstance(labels, np.ndarray):\n",
        "        raise TypeError(\"Labels harus berupa NumPy array\")\n",
        "    if labels.ndim != 1:\n",
        "        raise ValueError(\"Labels harus berupa array 1D\")\n",
        "\n",
        "    n_classes = np.max(labels) + 1\n",
        "    one_hot = np.zeros((labels.shape[0], n_classes), dtype=int)\n",
        "    one_hot[np.arange(labels.shape[0]), labels] = 1\n",
        "\n",
        "    return one_hot\n",
        "\n",
        "\n",
        "# TODO 4: Train-test split manual\n",
        "def train_test_split_numpy(X, y, test_size=0.2, random_state=None):\n",
        "    \"\"\"\n",
        "    Split dataset menjadi train dan test secara manual tanpa sklearn.\n",
        "    Input:\n",
        "      - X: fitur (np.ndarray)\n",
        "      - y: label (np.ndarray)\n",
        "      - test_size: proporsi test (float, default=0.2)\n",
        "      - random_state: untuk reproducibility\n",
        "    Output: X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    n_samples = X.shape[0]\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    test_size = int(n_samples * test_size)\n",
        "\n",
        "    test_idx = indices[:test_size]\n",
        "    train_idx = indices[test_size:]\n",
        "\n",
        "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
        "\n",
        "# Dataset simulasi\n",
        "np.random.seed(42)\n",
        "X = np.random.randn(100, 5) * 10 + 5  # Mean=5, Std=10\n",
        "\n",
        "# Normalisasi\n",
        "X_normalized = z_score_normalization(X)\n",
        "\n",
        "# Outlier Handling\n",
        "X_cleaned = handle_outliers(X_normalized)\n",
        "\n",
        "# One-hot Encoding\n",
        "labels = np.array([0, 1, 2, 0, 1, 2, 0])\n",
        "one_hot_labels = one_hot_encoding(labels)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split_numpy(X, np.random.randint(0, 3, 100), random_state=42)\n",
        "\n",
        "# Validasi\n",
        "assert X_normalized.shape == X.shape, \"Shape harus sama\"\n",
        "assert np.allclose(X_normalized.mean(), 0, atol=1e-10), \"Mean ~0 setelah normalisasi\"\n",
        "assert np.allclose(X_normalized.std(), 1, atol=1e-10), \"Std ~1 setelah normalisasi\"\n",
        "\n",
        "print(\"NumPy operations completed\")\n",
        "print(\"X_normalized:\\n\", X_normalized[:5])\n",
        "print(\"X_cleaned:\\n\", X_cleaned[:5])\n",
        "print(\"One-hot labels:\\n\", one_hot_labels)\n",
        "\n"
      ]
    }
  ]
}